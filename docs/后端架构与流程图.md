# åç«¯æ¶æ„ä¸æµç¨‹å›¾

**ä½¿ç”¨è¯´æ˜**: åœ¨æ”¯æŒ Mermaid çš„ Markdown ç¼–è¾‘å™¨ä¸­æŸ¥çœ‹ï¼ˆå¦‚ Typoraã€VS Code + Mermaid æ’ä»¶ã€GitHubï¼‰

---

## ğŸ“Š 1. æ•´ä½“ç³»ç»Ÿæ¶æ„

```mermaid
graph TB
    subgraph "å‰ç«¯ Frontend"
        UI1[æ¨¡å‹è®­ç»ƒé¡µé¢]
        UI2[è§†é¢‘ç”Ÿæˆé¡µé¢]
        UI3[äººæœºå¯¹è¯é¡µé¢]
    end
    
    subgraph "Flask è·¯ç”±å±‚"
        Route1["/model_training"]
        Route2["/video_generation"]
        Route3["/chat_system"]
        Route4["/save_audio"]
        Route5["/api/list_files"]
    end
    
    subgraph "åç«¯ä¸šåŠ¡é€»è¾‘"
        Trainer[model_trainer.py<br/>è®­ç»ƒè·¯ç”±]
        Generator[video_generator.py<br/>ç”Ÿæˆè·¯ç”±]
        Chat[chat_engine.py<br/>å¯¹è¯å¼•æ“]
        
        subgraph "SyncTalk æ¨¡å—"
            ST_Train[SyncTalk è®­ç»ƒ]
            ST_Gen[SyncTalk æ¨ç†]
        end
        
        subgraph "SelfTalk æ¨¡å— (æ–°å¢)"
            SFT_Train[selftalk_trainer.py]
            SFT_Gen[selftalk_generator.py]
        end
        
        subgraph "è¯­éŸ³å¤„ç†æ¨¡å— (æ–°å¢)"
            ASR[è¯­éŸ³è¯†åˆ«]
            TTS[tts_engine.py<br/>è¯­éŸ³å…‹éš†]
            LLM[å¤§æ¨¡å‹å¯¹è¯]
        end
    end
    
    subgraph "æ–‡ä»¶ç³»ç»Ÿ"
        Upload[uploads/<br/>ä¸Šä¼ æ–‡ä»¶]
        Static[static/<br/>ç”Ÿæˆç»“æœ]
        Models[æ¨¡å‹æ–‡ä»¶]
    end
    
    UI1 -->|POST è¡¨å•| Route1
    UI2 -->|POST è¡¨å•| Route2
    UI3 -->|POST è¡¨å•| Route3
    
    Route1 --> Trainer
    Route2 --> Generator
    Route3 --> Chat
    
    Trainer -->|SyncTalk| ST_Train
    Trainer -->|SelfTalk| SFT_Train
    
    Generator -->|SyncTalk| ST_Gen
    Generator -->|SelfTalk| SFT_Gen
    
    Chat --> ASR
    ASR --> LLM
    LLM --> TTS
    TTS --> SFT_Gen
    
    ST_Train --> Models
    SFT_Train --> Models
    ST_Gen --> Static
    SFT_Gen --> Static
    
    UI1 -.->|ä¸Šä¼ æ–‡ä»¶| Upload
    UI2 -.->|ä¸Šä¼ éŸ³é¢‘| Upload
    UI3 -.->|å½•éŸ³| Route4
    
    style SFT_Train fill:#FFE4B5
    style SFT_Gen fill:#FFE4B5
    style TTS fill:#FFE4B5
```

**å›¾ä¾‹**:
- ğŸŸ¨ æ©™è‰²æ¨¡å—ï¼šéœ€è¦æ–°å¼€å‘çš„æ¨¡å—

---

## ğŸ”„ 2. æ¨¡å‹è®­ç»ƒæµç¨‹å¯¹æ¯”

### 2.1 SyncTalk è®­ç»ƒæµç¨‹ï¼ˆå·²å®ç°ï¼‰

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant F as å‰ç«¯
    participant R as Flask è·¯ç”±
    participant T as model_trainer.py
    participant ST as SyncTalk Docker
    participant FS as æ–‡ä»¶ç³»ç»Ÿ

    U->>F: 1. é€‰æ‹© SyncTalkï¼Œä¸Šä¼ è§†é¢‘
    F->>R: 2. POST /model_training
    R->>T: 3. train_model(data)
    
    Note over T: data = {<br/>model_choice: 'SyncTalk',<br/>ref_video: path,<br/>gpu_choice: 'GPU0',<br/>epoch: 140<br/>}
    
    T->>ST: 4. è°ƒç”¨ run_synctalk.sh train
    
    rect rgb(200, 220, 240)
        Note over ST: Docker å†…éƒ¨æµç¨‹
        ST->>ST: 4.1 é¢„å¤„ç†è§†é¢‘
        ST->>ST: 4.2 ç¬¬ä¸€é˜¶æ®µè®­ç»ƒ
        ST->>ST: 4.3 ç¬¬äºŒé˜¶æ®µå¾®è°ƒ
    end
    
    ST->>FS: 5. ä¿å­˜æ¨¡å‹åˆ° SyncTalk/model/
    ST-->>T: 6. è®­ç»ƒå®Œæˆ
    T-->>R: 7. è¿”å›ç»“æœ
    R-->>F: 8. JSON å“åº”
    F-->>U: 9. æ˜¾ç¤ºè®­ç»ƒå®Œæˆ
```

### 2.2 SelfTalk è®­ç»ƒæµç¨‹ï¼ˆå¾…å®ç°ï¼‰

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant F as å‰ç«¯
    participant R as Flask è·¯ç”±
    participant T as model_trainer.py
    participant SFT as selftalk_trainer.py
    participant Main as SelfTalk/main.py
    participant FS as æ–‡ä»¶ç³»ç»Ÿ

    U->>F: 1. é€‰æ‹© SelfTalkï¼Œè®¾ç½®å‚æ•°
    F->>R: 2. POST /model_training
    R->>T: 3. train_model(data)
    
    Note over T: data = {<br/>model_choice: 'SelfTalk',<br/>dataset: 'vocaset',<br/>train_subjects: '...',<br/>epochs: 100,<br/>gpu_choice: 'GPU0'<br/>}
    
    T->>SFT: 4. train_selftalk(data)
    
    rect rgb(255, 228, 181)
        Note over SFT: selftalk_trainer.py
        SFT->>SFT: 4.1 è§£æå‚æ•°
        SFT->>SFT: 4.2 è®¾ç½®ç¯å¢ƒå˜é‡
        SFT->>SFT: 4.3 æ„å»ºå‘½ä»¤è¡Œå‚æ•°
    end
    
    SFT->>Main: 5. è°ƒç”¨ main.py --args
    
    rect rgb(200, 220, 240)
        Note over Main: SelfTalk è®­ç»ƒæµç¨‹
        Main->>Main: 5.1 åŠ è½½æ•°æ®
        Main->>Main: 5.2 åˆå§‹åŒ–æ¨¡å‹
        Main->>Main: 5.3 è®­ç»ƒå¾ªç¯
        Main->>Main: 5.4 éªŒè¯
    end
    
    Main->>FS: 6. ä¿å­˜æ¨¡å‹ vocaset/save/
    Main-->>SFT: 7. è®­ç»ƒå®Œæˆ
    SFT-->>T: 8. è¿”å›æ¨¡å‹è·¯å¾„
    T-->>R: 9. è¿”å›ç»“æœ
    R-->>F: 10. JSON å“åº”
    F-->>U: 11. æ˜¾ç¤ºè®­ç»ƒå®Œæˆ
```

---

## ğŸ¬ 3. è§†é¢‘ç”Ÿæˆæµç¨‹å¯¹æ¯”

### 3.1 SyncTalk æ¨ç†æµç¨‹ï¼ˆå·²å®ç°ï¼‰

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant F as å‰ç«¯
    participant R as Flask è·¯ç”±
    participant G as video_generator.py
    participant ST as SyncTalk Docker
    participant FS as æ–‡ä»¶ç³»ç»Ÿ

    U->>F: 1. é€‰æ‹©æ¨¡å‹ï¼Œä¸Šä¼ éŸ³é¢‘
    F->>R: 2. POST /video_generation
    R->>G: 3. generate_video(data)
    
    Note over G: data = {<br/>model_name: 'SyncTalk',<br/>model_param: 'model_dir',<br/>ref_audio: 'audio.wav',<br/>gpu_choice: 'GPU0'<br/>}
    
    G->>ST: 4. è°ƒç”¨ run_synctalk.sh infer
    
    rect rgb(200, 220, 240)
        Note over ST: Docker æ¨ç†æµç¨‹
        ST->>ST: 4.1 åŠ è½½æ¨¡å‹
        ST->>ST: 4.2 å¤„ç†éŸ³é¢‘
        ST->>ST: 4.3 ç”Ÿæˆè§†é¢‘
    end
    
    ST->>FS: 5. ä¿å­˜è§†é¢‘ results/test_audio.mp4
    G->>FS: 6. å¤åˆ¶åˆ° static/videos/
    G-->>R: 7. è¿”å›è§†é¢‘è·¯å¾„
    R-->>F: 8. JSON {video_path: '/static/videos/xxx.mp4'}
    F->>F: 9. æ›´æ–° video æ ‡ç­¾ src
    F-->>U: 10. æ’­æ”¾ç”Ÿæˆçš„è§†é¢‘ â–¶ï¸
```

### 3.2 SelfTalk æ¨ç†æµç¨‹ï¼ˆå¾…å®ç°ï¼‰

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant F as å‰ç«¯
    participant R as Flask è·¯ç”±
    participant G as video_generator.py
    participant SFG as selftalk_generator.py
    participant Model as SelfTalk æ¨¡å‹
    participant Render as æ¸²æŸ“å¼•æ“
    participant FS as æ–‡ä»¶ç³»ç»Ÿ

    U->>F: 1. é€‰æ‹© SelfTalkï¼Œä¸Šä¼ éŸ³é¢‘
    F->>R: 2. POST /video_generation
    R->>G: 3. generate_video(data)
    
    Note over G: data = {<br/>model_name: 'SelfTalk',<br/>model_path: 'xxx.pth',<br/>audio_path: 'audio.wav',<br/>subject: 'FaceTalk_xxx',<br/>gpu_choice: 'GPU0'<br/>}
    
    G->>SFG: 4. generate_video_selftalk(data)
    
    rect rgb(255, 228, 181)
        Note over SFG: selftalk_generator.py
        
        SFG->>SFG: 4.1 åŠ è½½æ¨¡å‹å’Œæ¨¡æ¿
        SFG->>SFG: 4.2 å¤„ç†éŸ³é¢‘ç‰¹å¾
        
        SFG->>Model: 4.3 model.predict(audio, template)
        Model-->>SFG: é¡¶ç‚¹åºåˆ— (N, V, 3)
        
        Note over SFG: å…³é”®ï¼šå°è£…é¢„æµ‹+æ¸²æŸ“ä¸¤æ­¥
        
        SFG->>Render: 4.4 render_sequence_meshes()
        
        loop æ¯ä¸€å¸§
            Render->>Render: æ¸²æŸ“ 3D ç½‘æ ¼
        end
        
        Render->>Render: 4.5 ffmpeg åˆå¹¶éŸ³è§†é¢‘
    end
    
    SFG->>FS: 5. ä¿å­˜è§†é¢‘ static/videos/selftalk_output/
    SFG-->>G: 6. è¿”å›è§†é¢‘è·¯å¾„
    G-->>R: 7. è¿”å›ç»“æœ
    R-->>F: 8. JSON å“åº”
    F->>F: 9. æ›´æ–° video æ ‡ç­¾
    F-->>U: 10. æ’­æ”¾ç”Ÿæˆçš„è§†é¢‘ â–¶ï¸
```

**å…³é”®ç‚¹**:
- âœ… å°è£…é¢„æµ‹å’Œæ¸²æŸ“ä¸¤ä¸ªæ­¥éª¤
- âœ… ç»Ÿä¸€æ¥å£ï¼Œå¯¹å¤–åªè¿”å›è§†é¢‘è·¯å¾„
- âœ… å¤„ç†ä¸´æ—¶æ–‡ä»¶æ¸…ç†

---

## ğŸ—£ï¸ 4. äººæœºå¯¹è¯å®Œæ•´æµç¨‹

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant F as å‰ç«¯
    participant R as Flask è·¯ç”±
    participant CE as chat_engine.py
    participant ASR as è¯­éŸ³è¯†åˆ«
    participant LLM as å¤§æ¨¡å‹
    participant TTS as tts_engine.py
    participant SFG as selftalk_generator.py
    participant FS as æ–‡ä»¶ç³»ç»Ÿ

    rect rgb(240, 248, 255)
        Note over U,F: ç¬¬ä¸€æ­¥ï¼šç”¨æˆ·å½•éŸ³
        U->>F: 1. ç‚¹å‡»å½•éŸ³æŒ‰é’® ğŸ¤
        U->>F: 2. è¯´è¯...
        U->>F: 3. åœæ­¢å½•éŸ³
        F->>R: 4. POST /save_audio (å½•éŸ³æ•°æ®)
        R->>FS: 5. ä¿å­˜ static/audios/recording_xxx.wav
    end

    rect rgb(255, 250, 240)
        Note over U,F: ç¬¬äºŒæ­¥ï¼šç”Ÿæˆ AI å›ç­”
        U->>F: 6. ä¸Šä¼ å‚è€ƒéŸ³é¢‘ï¼ˆéŸ³è‰²ï¼‰
        U->>F: 7. ç‚¹å‡»"å¼€å§‹å¯¹è¯"
        F->>R: 8. POST /chat_system
        R->>CE: 9. chat_response(data)
    end
    
    rect rgb(240, 255, 240)
        Note over CE,LLM: ç¬¬ä¸‰æ­¥ï¼šè¯­éŸ³è¯†åˆ« + AI å¯¹è¯
        CE->>ASR: 10. audio_to_text(å½•éŸ³)
        ASR-->>CE: 11. è¯†åˆ«æ–‡æœ¬
        CE->>LLM: 12. get_ai_response(æ–‡æœ¬)
        LLM-->>CE: 13. AI å›ç­”æ–‡æœ¬
    end
    
    rect rgb(255, 228, 181)
        Note over CE,TTS: ç¬¬å››æ­¥ï¼šè¯­éŸ³å…‹éš†
        CE->>TTS: 14. clone_voice(AIæ–‡æœ¬, å‚è€ƒéŸ³é¢‘)
        
        Note over TTS: ä½¿ç”¨ TTS æ¨¡å‹<br/>ï¼ˆGPT-SoVITS / CosyVoiceï¼‰
        
        TTS->>FS: 15. ä¿å­˜åˆæˆéŸ³é¢‘
        TTS-->>CE: 16. è¿”å›éŸ³é¢‘è·¯å¾„
    end
    
    rect rgb(255, 228, 181)
        Note over CE,SFG: ç¬¬äº”æ­¥ï¼šç”Ÿæˆè§†é¢‘
        CE->>SFG: 17. generate_video_selftalk({<br/>  audio_path: åˆæˆéŸ³é¢‘,<br/>  model_path: ...,<br/>  subject: ...}<br/>)
        SFG->>SFG: é¢„æµ‹ + æ¸²æŸ“
        SFG->>FS: 18. ä¿å­˜è§†é¢‘
        SFG-->>CE: 19. è¿”å›è§†é¢‘è·¯å¾„
    end
    
    CE-->>R: 20. è¿”å›è§†é¢‘è·¯å¾„
    R-->>F: 21. JSON å“åº”
    F->>F: 22. æ’­æ”¾è§†é¢‘ â–¶ï¸
    F-->>U: 23. çœ‹åˆ° AI è¯´è¯çš„è§†é¢‘
```

**æµç¨‹æ€»ç»“**:
1. ğŸ¤ ç”¨æˆ·å½•éŸ³æé—®
2. ğŸ”Š è¯­éŸ³è¯†åˆ« â†’ æ–‡æœ¬
3. ğŸ¤– å¤§æ¨¡å‹ç”Ÿæˆå›ç­”
4. ğŸµ è¯­éŸ³å…‹éš†ï¼ˆTTSï¼‰â†’ AI è¯­éŸ³
5. ğŸ¬ ç”Ÿæˆè¯´è¯è§†é¢‘ï¼ˆSelfTalkï¼‰

---

## ğŸ“¦ 5. æ•°æ®æµå›¾

```mermaid
graph LR
    subgraph "è¾“å…¥æ•°æ®"
        I1[ğŸ¥ è§†é¢‘æ–‡ä»¶<br/>SyncTalkè®­ç»ƒ]
        I2[ğŸµ éŸ³é¢‘æ–‡ä»¶<br/>wav/mp3]
        I3[ğŸ“Š é¡¶ç‚¹æ•°æ®<br/>npy]
        I4[ğŸ­ 3Dæ¨¡æ¿<br/>templates.pkl]
        I5[ğŸ¤ å½•éŸ³æ•°æ®<br/>Blob]
    end
    
    subgraph "å¤„ç†ä¸­é—´æ•°æ®"
        M1[ğŸ“ æ–‡æœ¬æ•°æ®<br/>è¯­éŸ³è¯†åˆ«ç»“æœ]
        M2[ğŸ¤– AIå›ç­”æ–‡æœ¬<br/>å¤§æ¨¡å‹è¾“å‡º]
        M3[ğŸ”¢ éŸ³é¢‘ç‰¹å¾<br/>Wav2Vec2]
        M4[ğŸ“ é¡¶ç‚¹åºåˆ—<br/>é¢„æµ‹ç»“æœ]
        M5[ğŸ–¼ï¸ æ¸²æŸ“å¸§<br/>å›¾åƒåºåˆ—]
    end
    
    subgraph "è¾“å‡ºæ•°æ®"
        O1[ğŸ¬ ç”Ÿæˆè§†é¢‘<br/>mp4]
        O2[ğŸ’¾ è®­ç»ƒæ¨¡å‹<br/>pthæ–‡ä»¶]
        O3[ğŸµ åˆæˆéŸ³é¢‘<br/>TTSè¾“å‡º]
    end
    
    I1 --> SyncTalkè®­ç»ƒ
    SyncTalkè®­ç»ƒ --> O2
    
    I2 --> SyncTalkæ¨ç†
    I2 --> SelfTalkæ¨ç†
    SyncTalkæ¨ç† --> O1
    
    I2 --> M3
    I3 --> SelfTalkè®­ç»ƒ
    I4 --> SelfTalkè®­ç»ƒ
    SelfTalkè®­ç»ƒ --> O2
    
    I4 --> SelfTalkæ¨ç†
    M3 --> M4
    M4 --> M5
    M5 --> O1
    
    I5 --> è¯­éŸ³è¯†åˆ«
    è¯­éŸ³è¯†åˆ« --> M1
    M1 --> å¤§æ¨¡å‹
    å¤§æ¨¡å‹ --> M2
    M2 --> TTS
    I2 -- éŸ³è‰²å‚è€ƒ --> TTS
    TTS --> O3
    O3 --> SelfTalkæ¨ç†
    
    style I1 fill:#E8F5E9
    style I2 fill:#E8F5E9
    style I3 fill:#E8F5E9
    style I4 fill:#E8F5E9
    style I5 fill:#E8F5E9
    
    style M1 fill:#FFF3E0
    style M2 fill:#FFF3E0
    style M3 fill:#FFF3E0
    style M4 fill:#FFF3E0
    style M5 fill:#FFF3E0
    
    style O1 fill:#E3F2FD
    style O2 fill:#E3F2FD
    style O3 fill:#E3F2FD
```

---

## ğŸ‘¥ 6. ä»»åŠ¡åˆ†å·¥ä¸ä¾èµ–å…³ç³»

```mermaid
graph TB
    subgraph "æ ¸å¿ƒå¼€å‘ä»»åŠ¡"
        T1[ğŸ“Š é¡¹ç›®åˆ†æ<br/>âœ… å·²å®Œæˆ]
        T2[ğŸ¬ selftalk_generator.py<br/>â±ï¸ 4å°æ—¶<br/>ğŸ”´ æœ¬å‘¨]
        T3[ğŸ”„ é‡æ„ video_generator.py<br/>â±ï¸ 2å°æ—¶]
        T4[ğŸ”„ é‡æ„ model_trainer.py<br/>â±ï¸ 2å°æ—¶]
        T5[ğŸ“ selftalk_trainer.py<br/>â±ï¸ 4å°æ—¶<br/>ğŸ”´ æœ¬å‘¨]
        T6[ğŸ“¤ æ–‡ä»¶ä¸Šä¼ æ¥å£<br/>â±ï¸ 3å°æ—¶]
        T7[ğŸ¤ å®Œå–„å½•éŸ³ä¿å­˜<br/>â±ï¸ 2å°æ—¶]
        T8[ğŸ“‹ æ–‡ä»¶åˆ—è¡¨æ¥å£<br/>â±ï¸ 2å°æ—¶]
        T9[ğŸ” TTS æ–¹æ¡ˆè°ƒç ”<br/>â±ï¸ 3å°æ—¶<br/>âšª ä¸‹å‘¨]
        T10[ğŸµ tts_engine.py<br/>â±ï¸ 6å°æ—¶]
        T11[ğŸ”— é›†æˆ TTS åˆ° chat_engine<br/>â±ï¸ 2å°æ—¶]
        T12[ğŸ“ æ¥å£æ–‡æ¡£<br/>â±ï¸ 2å°æ—¶]
        T13[ğŸ§ª å•å…ƒæµ‹è¯•<br/>â±ï¸ 3å°æ—¶<br/>âšª ç¬¬ä¸‰é˜¶æ®µ]
    end
    
    subgraph "åä½œä»»åŠ¡"
        C1[ğŸ¤ æ¥å£å¯¹æ¥æµ‹è¯•]
        C2[ğŸ› è”åˆè°ƒè¯•]
        C3[ğŸ“š æ–‡æ¡£æ›´æ–°]
    end
    
    T1 --> T2
    T1 --> T5
    
    T2 --> T3
    T5 --> T4
    
    T3 --> C1
    T4 --> C1
    T6 --> C1
    
    T2 --> T9
    T9 --> T10
    T10 --> T11
    
    T7 --> T11
    
    C1 --> C2
    C2 --> C3
    
    T11 --> T13
    
    style T1 fill:#90EE90
    style T2 fill:#FFB6C1
    style T3 fill:#FFB6C1
    style T4 fill:#FFB6C1
    style T5 fill:#FFB6C1
    style T6 fill:#FFB6C1
    style T7 fill:#FFB6C1
    style T8 fill:#FFB6C1
    style T9 fill:#D3D3D3
    style T10 fill:#D3D3D3
    style T11 fill:#D3D3D3
    style T12 fill:#D3D3D3
    style T13 fill:#D3D3D3
    
    style C1 fill:#87CEEB
    style C2 fill:#87CEEB
    style C3 fill:#87CEEB
```

**å›¾ä¾‹**:
- ğŸŸ¢ ç»¿è‰²ï¼šå·²å®Œæˆ
- ğŸ”´ ç²‰è‰²ï¼šæœ¬å‘¨ä»»åŠ¡ï¼ˆP0ï¼‰
- âšª ç°è‰²ï¼šåç»­ä»»åŠ¡

---

## ğŸ”— 7. å‰åç«¯ API äº¤äº’

### 7.1 è®­ç»ƒæ¥å£

```mermaid
sequenceDiagram
    participant F as å‰ç«¯
    participant A as Flask App
    participant B as Backend

    Note over F: ç”¨æˆ·å¡«å†™è®­ç»ƒè¡¨å•
    
    F->>A: POST /model_training
    Note right of F: Content-Type: multipart/form-data<br/>{<br/>  model_choice: 'SelfTalk',<br/>  dataset: 'vocaset',<br/>  epochs: 100,<br/>  gpu_choice: 'GPU0',<br/>  ref_video: File (SyncTalk),<br/>  train_subjects: '...'<br/>}
    
    A->>B: train_model(data)
    
    rect rgb(255, 228, 181)
        Note over B: åç«¯å¤„ç†<br/>3-10 å°æ—¶ï¼ˆå–å†³äºæ•°æ®é‡ï¼‰
        B->>B: è®­ç»ƒæ¨¡å‹...
    end
    
    B-->>A: è¿”å›: "è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹ä¿å­˜åœ¨ xxx"
    A-->>F: JSON Response
    Note left of A: {<br/>  "status": "success",<br/>  "message": "è®­ç»ƒå®Œæˆ",<br/>  "model_path": "..."<br/>}
    
    F->>F: æ˜¾ç¤ºæˆåŠŸæç¤º
```

### 7.2 ç”Ÿæˆæ¥å£

```mermaid
sequenceDiagram
    participant F as å‰ç«¯
    participant A as Flask App
    participant B as Backend

    Note over F: ç”¨æˆ·ä¸Šä¼ éŸ³é¢‘
    
    F->>A: POST /video_generation
    Note right of F: {<br/>  model_name: 'SelfTalk',<br/>  model_path: 'xxx.pth',<br/>  audio_path: 'test.wav',<br/>  subject: 'FaceTalk_xxx',<br/>  gpu_choice: 'GPU0'<br/>}
    
    A->>B: generate_video(data)
    
    rect rgb(255, 228, 181)
        Note over B: åç«¯å¤„ç†<br/>30ç§’ - 2åˆ†é’Ÿ
        B->>B: é¢„æµ‹ + æ¸²æŸ“...
    end
    
    B-->>A: è¿”å›: "static/videos/xxx.mp4"
    A-->>F: JSON Response
    Note left of A: {<br/>  "status": "success",<br/>  "video_path": "/static/videos/xxx.mp4"<br/>}
    
    F->>F: æ›´æ–° video æ ‡ç­¾
    F->>F: æ’­æ”¾è§†é¢‘
```

### 7.3 å¯¹è¯æ¥å£

```mermaid
sequenceDiagram
    participant F as å‰ç«¯
    participant A as Flask App
    participant B as Backend

    Note over F: ç”¨æˆ·å½•éŸ³ + ä¸Šä¼ å‚è€ƒéŸ³é¢‘
    
    F->>A: POST /save_audio (å½•éŸ³)
    A-->>F: {filepath: "..."}
    
    F->>A: POST /chat_system
    Note right of F: {<br/>  recording_path: '...',<br/>  reference_audio: '...',<br/>  model_path: '...',<br/>  subject: '...'<br/>}
    
    A->>B: chat_response(data)
    
    rect rgb(255, 228, 181)
        Note over B: å®Œæ•´æµç¨‹<br/>1-3 åˆ†é’Ÿ
        B->>B: è¯­éŸ³è¯†åˆ« (5s)
        B->>B: AI å¯¹è¯ (2s)
        B->>B: è¯­éŸ³å…‹éš† (10s)
        B->>B: è§†é¢‘ç”Ÿæˆ (1-2min)
    end
    
    B-->>A: è¿”å›: "static/videos/chat_xxx.mp4"
    A-->>F: JSON Response
    Note left of A: {<br/>  "status": "success",<br/>  "video_path": "/static/videos/chat_xxx.mp4",<br/>  "ai_text": "AIå›ç­”å†…å®¹"<br/>}
    
    F->>F: æ˜¾ç¤º AI æ–‡æœ¬
    F->>F: æ’­æ”¾è§†é¢‘
```

---

## ğŸ¯ 8. æœ¬å‘¨å¼€å‘é‡ç‚¹

```mermaid
gantt
    title æœ¬å‘¨ä»»åŠ¡ç”˜ç‰¹å›¾ (2025-11-15 ~ 2025-11-22)
    dateFormat  YYYY-MM-DD
    
    section æ ¸å¿ƒå¼€å‘
    é¡¹ç›®åˆ†æï¼ˆå·²å®Œæˆï¼‰    :done, t1, 2025-11-15, 1d
    selftalk_generator.py :active, t2, 2025-11-15, 2d
    selftalk_trainer.py   :active, t3, 2025-11-15, 2d
    é‡æ„ video_generator  :t4, after t2, 1d
    é‡æ„ model_trainer    :t5, after t4, 1d
    æ–‡ä»¶ä¸Šä¼ æ¥å£          :t6, after t3, 1d
    å½•éŸ³ä¿å­˜åŠŸèƒ½          :t7, after t6, 1d
    æµ‹è¯•ä¸ä¿®å¤            :t8, after t5, 2d
    
    section åä½œ
    æ¥å£å¯¹æ¥              :c1, 2025-11-18, 1d
    è”åˆæµ‹è¯•              :c2, 2025-11-19, 2d
    æ–‡æ¡£æ›´æ–°              :c3, 2025-11-21, 1d
```

---

## ğŸ“ å¿«é€Ÿå‚è€ƒ

### æ ¸å¿ƒå¼€å‘æ–‡ä»¶

```
backend/
â”œâ”€â”€ selftalk_generator.py  â† ğŸ¯ æ¨ç†æ¨¡å—
â”œâ”€â”€ selftalk_trainer.py    â† ğŸ¯ è®­ç»ƒæ¨¡å—
â”œâ”€â”€ video_generator.py     â† éœ€è¦é‡æ„
â”œâ”€â”€ model_trainer.py       â† éœ€è¦é‡æ„
â””â”€â”€ tts_engine.py          â† è¯­éŸ³å…‹éš†æ¨¡å—
```

### å…³é”®æ•°æ®ç»“æ„

```python
# è®­ç»ƒæ¥å£è¾“å…¥
train_data = {
    'model_choice': 'SelfTalk',
    'dataset': 'vocaset',
    'epochs': 100,
    'gpu_choice': 'GPU0',
    'train_subjects': 'FaceTalk_170728_03272_TA ...',
    'val_subjects': 'FaceTalk_170811_03275_TA ...',
}

# æ¨ç†æ¥å£è¾“å…¥
generate_data = {
    'model_name': 'SelfTalk',
    'model_path': 'SelfTalk/vocaset/save/xxx/100_model.pth',
    'audio_path': 'uploads/audios/test.wav',
    'subject': 'FaceTalk_170908_03277_TA',
    'gpu_choice': 'GPU0',
    'dataset': 'vocaset',
    'feature_dim': 512
}
```

---

**æŸ¥çœ‹æç¤º**: 
- åœ¨ VS Code ä¸­å®‰è£… "Markdown Preview Mermaid Support" æ’ä»¶
- æˆ–ä½¿ç”¨ Typora ç¼–è¾‘å™¨
- æˆ–æ¨é€åˆ° GitHub ååœ¨çº¿æŸ¥çœ‹

